# Copy this file to .env and fill in your values
# Configure EITHER Azure OpenAI OR standard OpenAI (not both)

# =============================================================================
# Server Configuration
# =============================================================================
# Host and port for the uvicorn server
UVICORN_HOST=0.0.0.0
UVICORN_PORT=3001

# =============================================================================
# Logging Configuration
# =============================================================================
# Set to 'true' to write logs to a timestamped file in the /logs folder
# useful for debugging issues when running locally
# WRITE_LOG_TO_FILE=false

# =============================================================================
# Azure OpenAI Configuration (checked first)
# =============================================================================
# Your Azure OpenAI endpoint URL (e.g., https://your-resource.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=

# Your Azure OpenAI API key
AZURE_OPENAI_API_KEY=

# The deployment name for your model (e.g., gpt-5.1-chat)
AZURE_OPENAI_DEPLOYMENT=

# Azure Application Insights connection string for Agent Framework telemetry (optional)
# When set, traces, logs, and metrics are exported to Azure Monitor
APPLICATIONINSIGHTS_CONNECTION_STRING=

# API version (optional, default: 2024-12-01-preview)
# OPENAI_API_VERSION=2024-12-01-preview

# =============================================================================
# Standard OpenAI Configuration (used if Azure not configured)
# =============================================================================
# Your OpenAI API key from https://platform.openai.com/api-keys
# OPENAI_API_KEY=

# Model name to use (optional, default: gpt-5.1-chat)
# OPENAI_MODEL=gpt-5.1-chat

# Custom base URL for OpenAI-compatible APIs (optional)
# Useful for local LLMs or alternative providers (e.g., http://localhost:1234/v1)
# OPENAI_BASE_URL=